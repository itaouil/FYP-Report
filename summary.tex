Rudimentary robots have been part of our lives since the early stage of the industrial revolution. We interact with servicing systems almost every day, such as TV's, smartphones and self-checkout systems. This is an unstoppable trend and in the future advanced robotic systems will become more present in human environments in a variety of areas, including assistance, rescue and logistics. Moreover, interactions between humans are defined by a set of precise protocols, in fact, we would not jump in front of a queue or invade someone else's space in a common area without asking permission first. For robots to integrate they will have to comply to some ethical, moral and social rules that govern our way of being humans. The aim of this project is to contribute to the human-robot interaction domain, by developing an open-source ROS package able to estimate people's 3D position in the environment. High level of confidence and robustness were reached using deep-learning techniques to detect people in the RGB frame. RGB-D sensory data were also used to compute detections' distances with the relative 3D position in the map, using several algorithms and techniques.
