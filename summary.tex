Rudimentary robots have been part of our lives since the early stage of the industrial revolution. We interact with servicing robots almost every day, such as TV's, smartphones and self-checkout systems. This is an unstoppable trend and in the future robots will become more present in human environments in a variety of areas, including assistance, grunt work and logistics. Moreover, interactions between humans are defined by a set of precise protocols, in fact, we would not jump in front of a queue or invade someone else's space in a common area without asking permission first. Therefore, for robots to be able to integrate and more importantly for humans to accept such an integration, they will have to comply to some ethical, moral and social rules that govern our way of being humans. This project’s aim was to contribute to the human-robot interaction domain by developing an open-source ROS package that can estimate people’s 3D pose in the environment. High level of confidence and robustness were reached using deep-learning techniques to detect people in the RGB frame and RGB-D sensory data were also used to compute detections' distances with the relative 3D pose in the map using several algorithms and techniques.
