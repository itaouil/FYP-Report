\chapter{Architecture \& Modules Integration}
\label{chapter5}

\section{Architecture}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=\linewidth]{images/chapter6_architecture.png}
  \end{center}
  \caption{Project's architecture.}
  \label{fig:architecture}
\end{figure}

The final solution has three main components to it:

\begin{enumerate}
	\item The conversion script that converts the \textbf{image\_rect\_color} into an OpenCV format.
    \item The detection script that detects people in the converted frame.
    \item The pose script that computes the detection's distance and finds its 3D pose in the map frame.
\end{enumerate}

All of the components do sit on top of the ROS middle-ware whose utilities include ROS services, standard messages and publish-subscribe communication paradigms among others. Moreover, it is essential to have a ROS master available for the package to work as this handles the topics and makes available the required topics such as the rectified coloured image and the rectified depth-image, where in this occasion these were made available by TIAGo's bring-up and its ROS master export in the development machine. 

Lastly ROS services were used for module-intra-communication. Figure 5.1 gives an overview of how the communication happens and in which order between the various components.

\subsection{Communication Logic}

\subsection{Conversion}

The conversion module was implemented via a set of routines which are called by the main within the same file, which subscribes to the rectified colour and depth image, converts the former and sends a service request to the detection module, which will respond with a success or failure message (once the whole communication chain is resolved).

\subsection{Detection}

The detection module waits until the service request from the conversion script is received, and upon which it runs the feed-forward process, creates a detections message and passes this to the next module via a different service request.

\subsection{3D Pose}

Finally the pose module receives the request from the detection module, computes the distance for every detection its 3D pose in the map. Once done, a set of markers are published to RVIZ along with a custom poses message with the 3D pose for each detection, and a response notifying the success of failure of the process is sent back to the service caller.

\section{Modules Integration}

The original plan for the development consisted in having separate modules for each task that operate independently of each other, and that would have access to each others computations via the published topics. 

However, this had to be reconsidered when the pose and detection modules had to be integrated. In fact, given that the subscribed depth-image published by TIAGO's interface has a lower publishing rate then the coloured image, a synchronisation problem happened, where the wrong depth ROI\footnote{Region of Interest} was accessed because of the delay, which ultimately consisted in computing the wrong distance and therefore the wrong 3D pose.

\subsection{Time Synchroniser}

To solve the synchronisation issue an approximate time synchroniser was used. More precisely the \textbf{ApproximateTimeSynchroniser} routine made available by the message\_filters library allows the subscription to multiple topics whose callback function is called only when the timestamps differences are within a certain threshold. 

Therefore, two separate subscriptions called \textbf{rgb\_sub} and \textbf{depth\_sub} were made respectively to the raw rectified image and the rectified depth-image topics, in the \textbf{cv\_conversion.py} script, which consequently got chained together using the time synchronizer with a threshold error of at most 0.5 seconds, as shown below. Of course, the bigger the threshold, the greater the delay, hence a good empirical value had to be found. The synchronisation is then binded to a callback function called \textbf{processSubscriptions} using the \textbf{registerCallback} routine, also made available by the message\_filters library as follows.

\begin{lstlisting}
import message_filters as mf
ats = mf.ApproximateTimeSynchronizer([rgb_sub, depth_sub], slop=0.5)
ats.registerCallback(processSubscriptions)
\end{lstlisting}

\subsection{ROS Services}

Two choices were available for the module-intra-communication, by either using standard publish-subscribe communication or an RPC based style via services. 

The original idea was to use the former type of communication, as it would allow a more flexible and modular usage of the package given that if a user only wants to use a specific component of the package, only the required module would have to be executed. However, due to the RGB-depth synchronisation problem, and the fact that the subscriptions are both made in one place (the conversion script) and not in their relative module as originally planned (so rgb\_sub in the conversion module and depth\_sub in the pose module) the latter type of communication via ROS services was preferred for an easier message exchange. In fact, via a service mean, the collected ROS messages at subscription time can be passed forward to server nodes with simple \textbf{srv} files rather then having to publish them all over again.

Hence a \textbf{srv} folder is created in the same path as the msg folder at the root of the catkin package, in which two services are defined, a detection one called \textbf{RequestDetection.srv} that requests the feed-forward process to the detection module, and that has as a client the conversion component and as the server the detection one. A pose service named \textbf{RequestPose} is also declared, which requests the actual distance and 3D pose computation, and whose client is the detection module and server the pose component. The two service declarations for the RequestDetection.srv(left) and the RequestPose.srv(right) are as follows:

\begin{multicols}{2}
  \begin{itemize}
    \item sensor\_msgs/Image depth
    \item - - -
    \item string res
  \end{itemize}

  \columnbreak

  \begin{itemize}
    \item Detections detections
    \item sensor\_msgs/Image depth
    \item - - -
    \item string res
  \end{itemize}
\end{multicols}

A typical service message is made of a request and response declaration separated by a dotted line. 

In the case of the detection service the input passed through the service request by the conversion script is only the synchronised image, as the RGB image is stored on the disk. The response expected by the service is a string determining either the success of failure of the service, which is then printed to the console for the user to keep track of the process.

Similarly the pose service request expects as input the detections computed by the neural network as a Detections message, as well as the depth-image originally retrieved during the conversion process at the beginning of the chain. The response expected is again a string suggesting the failure or success of the process.

The service request are blocking, which means that the module is idled as it waits for the server to come up or the response message to come back, which is something to improve upon in the future.


